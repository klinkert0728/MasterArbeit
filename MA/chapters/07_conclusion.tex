\section{Conclusion}
\label{cha:conclusion}
This thesis explores whether performance results from microbenchmarks can reliably predict the application-level performance of VictoriaMetrics and assesses whether those findings align with or contradict the approach proposed by Grambow et al. \cite{grambow}. The goal was to replicate or challenge their results using a different methodology while using the same system under test, VictoriaMetrics, by directly testing whether a reduced microbenchmark suite can stand in for more complex application benchmarks by applying a ridge regression model. \\
Ridge regression was chosen for its robustness against multicollinearity to model and anticipate the \ac{SUT} application performance using microbenchmark data. The hypothesis was that if the microbenchmarks captured the performance-relevant operations accurately, the model would learn the relationship between those low-level indicators and the overall application mean query rate. However, the outcomes of this study suggest that the ridge regression model frequently exhibited overfitting and was ultimately unable to deliver reliable and accurate application-level performance predictions. \\
This research did not uncover a strong, actionable correlation between microbenchmark outcomes and full-scale application performance. While microbenchmarks often provide quick feedback on particular functions or code paths, our findings underscore that such fine-grained measurements may not reliably aggregate into accurate application-level predictionsâ€”at least not in the ridge regression context used here. The high degree of collinearity among features presented significant challenges. Although ridge regression is supposed to mitigate multicollinearity, it was not enough as we encountered strong correlations with the set of features, which reduced the model's capability to predict using the training data. This finding highlights that increasing the quantity of microbenchmark data is unlikely to resolve overfitting if the core features set remains heavily collinear; therefore, this research suggests further research to provide more accurate results. Due to this research results, this work could neither confirm nor refute Grambow et al. \cite{grambow} approach regarding microbenchmarks' predictive power for application performance due to the high collinearity leading to an overfitting model.
